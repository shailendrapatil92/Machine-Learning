
# coding: utf-8

# In[1]:

# The data has 16562 attributes

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from __future__ import division
import sklearn
from sklearn import feature_selection


# In[2]:

#Making the target variable as the last column, because for the test data we need to have the same indexes for preprocessing as training data
dataset = pd.read_csv('/Users/shailendrapatil/Downloads/DScasestudy1.txt',sep ='\t')
b = pd.DataFrame(data=dataset[[0]])
dataset=dataset.drop(dataset.columns[0],axis=1)
dataset['response']=b


###Test data can will be imported here 
#dataset_test = pd.read_csv('test_data,sep ='\t')


# In[6]:

dataset.head()
len(dataset)


# In[176]:

#Checking for any missing values
sum(np.sum(pd.isnull(dataset) == True))
#check missing values for test data as well and then append accordingly


# In[177]:

# Few columns have standard deviation as '0' that is all the entries of column are wither completly 0 or completly 1
#and hence it wont have any effect on target variable
index =[]
for i in range(len(dataset.columns)):
    if(float(np.std(dataset[[i]]))==0.0):
        index.append(i)


# In[178]:

len(index)


# In[179]:

#This columns will have no importance in our analysis. So we will remove those columns from our dataset
dataset_clean=dataset.drop(dataset.columns[index],axis=1)
len(dataset_clean.columns)

### Code for test data can be added here similar to this 


# In[180]:

dataset_clean


# In[188]:

#Taking the response variable
target = dataset_clean[[-1]].as_matrix()


# In[227]:

# feature selection
#Below package check Mutual information between attributes and target variable
#If it returns 0 it means target and feature are independent
#If it returns greater than 0 it means target and feature are dependent
from sklearn import feature_selection
index_MI=sklearn.feature_selection.mutual_info_classif(dataset_clean.ix[:,0:-1],target,discrete_features='auto',n_neighbors=3,copy=True,random_state=None)


# In[190]:

index_MI


# In[191]:

#No of colums for which mutual information is 0 i.e the Target variable and attributes are independent
len(index_MI[index_MI==0])


# In[192]:

dataset_clean=dataset_clean.drop(dataset_clean.ix[:,0:].columns[index_MI==0],axis=1)
len(dataset_clean.columns)
#Same process for test data


# In[193]:

dataset_clean


# In[194]:

x=dataset_clean.iloc[:, :-1].values
y=dataset_clean.iloc[:,-1].values
len(x[1,])


# In[251]:

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)


# In[252]:

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(x_train, y_train)


# In[253]:

y_pred = classifier.predict(x_test)


# In[254]:

len(y_pred)


# In[255]:

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
cm

